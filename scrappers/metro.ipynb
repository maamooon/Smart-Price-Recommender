{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DWKfds7zdco0",
        "outputId": "30f85a00-b629-472b-db94-54fd60fa7e3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting playwright\n",
            "  Downloading playwright-1.55.0-py3-none-manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting pyee<14,>=13 (from playwright)\n",
            "  Downloading pyee-13.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in /usr/local/lib/python3.12/dist-packages (from playwright) (3.2.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from pyee<14,>=13->playwright) (4.15.0)\n",
            "Downloading playwright-1.55.0-py3-none-manylinux1_x86_64.whl (45.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m45.9/45.9 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyee-13.0.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyee, playwright\n",
            "Successfully installed playwright-1.55.0 pyee-13.0.0\n",
            "Downloading Chromium 140.0.7339.16 (playwright build v1187)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/chromium/1187/chromium-linux.zip\u001b[22m\n",
            "\u001b[1G173.7 MiB [] 0% 11.5s\u001b[0K\u001b[1G173.7 MiB [] 0% 23.2s\u001b[0K\u001b[1G173.7 MiB [] 0% 15.3s\u001b[0K\u001b[1G173.7 MiB [] 0% 10.0s\u001b[0K\u001b[1G173.7 MiB [] 0% 7.9s\u001b[0K\u001b[1G173.7 MiB [] 1% 6.4s\u001b[0K\u001b[1G173.7 MiB [] 1% 5.8s\u001b[0K\u001b[1G173.7 MiB [] 2% 5.2s\u001b[0K\u001b[1G173.7 MiB [] 2% 4.5s\u001b[0K\u001b[1G173.7 MiB [] 3% 4.2s\u001b[0K\u001b[1G173.7 MiB [] 3% 4.0s\u001b[0K\u001b[1G173.7 MiB [] 4% 3.8s\u001b[0K\u001b[1G173.7 MiB [] 5% 3.6s\u001b[0K\u001b[1G173.7 MiB [] 5% 3.7s\u001b[0K\u001b[1G173.7 MiB [] 5% 4.0s\u001b[0K\u001b[1G173.7 MiB [] 6% 3.8s\u001b[0K\u001b[1G173.7 MiB [] 7% 3.6s\u001b[0K\u001b[1G173.7 MiB [] 8% 3.6s\u001b[0K\u001b[1G173.7 MiB [] 9% 3.5s\u001b[0K\u001b[1G173.7 MiB [] 9% 3.4s\u001b[0K\u001b[1G173.7 MiB [] 10% 3.4s\u001b[0K\u001b[1G173.7 MiB [] 11% 3.4s\u001b[0K\u001b[1G173.7 MiB [] 12% 3.3s\u001b[0K\u001b[1G173.7 MiB [] 13% 3.1s\u001b[0K\u001b[1G173.7 MiB [] 14% 3.0s\u001b[0K\u001b[1G173.7 MiB [] 15% 2.9s\u001b[0K\u001b[1G173.7 MiB [] 15% 2.8s\u001b[0K\u001b[1G173.7 MiB [] 16% 2.8s\u001b[0K\u001b[1G173.7 MiB [] 17% 2.7s\u001b[0K\u001b[1G173.7 MiB [] 18% 2.6s\u001b[0K\u001b[1G173.7 MiB [] 19% 2.4s\u001b[0K\u001b[1G173.7 MiB [] 21% 2.3s\u001b[0K\u001b[1G173.7 MiB [] 22% 2.4s\u001b[0K\u001b[1G173.7 MiB [] 23% 2.3s\u001b[0K\u001b[1G173.7 MiB [] 25% 2.1s\u001b[0K\u001b[1G173.7 MiB [] 26% 2.0s\u001b[0K\u001b[1G173.7 MiB [] 28% 1.9s\u001b[0K\u001b[1G173.7 MiB [] 29% 1.8s\u001b[0K\u001b[1G173.7 MiB [] 31% 1.7s\u001b[0K\u001b[1G173.7 MiB [] 32% 1.7s\u001b[0K\u001b[1G173.7 MiB [] 33% 1.6s\u001b[0K\u001b[1G173.7 MiB [] 34% 1.6s\u001b[0K\u001b[1G173.7 MiB [] 35% 1.5s\u001b[0K\u001b[1G173.7 MiB [] 37% 1.5s\u001b[0K\u001b[1G173.7 MiB [] 38% 1.4s\u001b[0K\u001b[1G173.7 MiB [] 39% 1.4s\u001b[0K\u001b[1G173.7 MiB [] 40% 1.4s\u001b[0K\u001b[1G173.7 MiB [] 41% 1.4s\u001b[0K\u001b[1G173.7 MiB [] 42% 1.4s\u001b[0K\u001b[1G173.7 MiB [] 43% 1.4s\u001b[0K\u001b[1G173.7 MiB [] 44% 1.3s\u001b[0K\u001b[1G173.7 MiB [] 46% 1.3s\u001b[0K\u001b[1G173.7 MiB [] 47% 1.3s\u001b[0K\u001b[1G173.7 MiB [] 48% 1.2s\u001b[0K\u001b[1G173.7 MiB [] 49% 1.2s\u001b[0K\u001b[1G173.7 MiB [] 51% 1.2s\u001b[0K\u001b[1G173.7 MiB [] 52% 1.1s\u001b[0K\u001b[1G173.7 MiB [] 53% 1.1s\u001b[0K\u001b[1G173.7 MiB [] 54% 1.0s\u001b[0K\u001b[1G173.7 MiB [] 55% 1.0s\u001b[0K\u001b[1G173.7 MiB [] 57% 1.0s\u001b[0K\u001b[1G173.7 MiB [] 58% 0.9s\u001b[0K\u001b[1G173.7 MiB [] 59% 0.9s\u001b[0K\u001b[1G173.7 MiB [] 60% 0.9s\u001b[0K\u001b[1G173.7 MiB [] 61% 0.9s\u001b[0K\u001b[1G173.7 MiB [] 62% 0.9s\u001b[0K\u001b[1G173.7 MiB [] 63% 0.8s\u001b[0K\u001b[1G173.7 MiB [] 64% 0.8s\u001b[0K\u001b[1G173.7 MiB [] 65% 0.8s\u001b[0K\u001b[1G173.7 MiB [] 66% 0.7s\u001b[0K\u001b[1G173.7 MiB [] 68% 0.7s\u001b[0K\u001b[1G173.7 MiB [] 69% 0.7s\u001b[0K\u001b[1G173.7 MiB [] 70% 0.7s\u001b[0K\u001b[1G173.7 MiB [] 71% 0.6s\u001b[0K\u001b[1G173.7 MiB [] 72% 0.6s\u001b[0K\u001b[1G173.7 MiB [] 73% 0.6s\u001b[0K\u001b[1G173.7 MiB [] 74% 0.6s\u001b[0K\u001b[1G173.7 MiB [] 76% 0.5s\u001b[0K\u001b[1G173.7 MiB [] 77% 0.5s\u001b[0K\u001b[1G173.7 MiB [] 78% 0.5s\u001b[0K\u001b[1G173.7 MiB [] 79% 0.4s\u001b[0K\u001b[1G173.7 MiB [] 80% 0.4s\u001b[0K\u001b[1G173.7 MiB [] 81% 0.4s\u001b[0K\u001b[1G173.7 MiB [] 82% 0.4s\u001b[0K\u001b[1G173.7 MiB [] 84% 0.3s\u001b[0K\u001b[1G173.7 MiB [] 85% 0.3s\u001b[0K\u001b[1G173.7 MiB [] 86% 0.3s\u001b[0K\u001b[1G173.7 MiB [] 87% 0.3s\u001b[0K\u001b[1G173.7 MiB [] 88% 0.2s\u001b[0K\u001b[1G173.7 MiB [] 89% 0.2s\u001b[0K\u001b[1G173.7 MiB [] 90% 0.2s\u001b[0K\u001b[1G173.7 MiB [] 91% 0.2s\u001b[0K\u001b[1G173.7 MiB [] 92% 0.1s\u001b[0K\u001b[1G173.7 MiB [] 93% 0.1s\u001b[0K\u001b[1G173.7 MiB [] 94% 0.1s\u001b[0K\u001b[1G173.7 MiB [] 95% 0.1s\u001b[0K\u001b[1G173.7 MiB [] 96% 0.1s\u001b[0K\u001b[1G173.7 MiB [] 98% 0.0s\u001b[0K\u001b[1G173.7 MiB [] 99% 0.0s\u001b[0K\u001b[1G173.7 MiB [] 100% 0.0s\u001b[0K\n",
            "Chromium 140.0.7339.16 (playwright build v1187) downloaded to /root/.cache/ms-playwright/chromium-1187\n",
            "Downloading Chromium Headless Shell 140.0.7339.16 (playwright build v1187)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/chromium/1187/chromium-headless-shell-linux.zip\u001b[22m\n",
            "\u001b[1G104.3 MiB [] 0% 0.0s\u001b[0K\u001b[1G104.3 MiB [] 0% 14.5s\u001b[0K\u001b[1G104.3 MiB [] 0% 9.4s\u001b[0K\u001b[1G104.3 MiB [] 0% 6.1s\u001b[0K\u001b[1G104.3 MiB [] 1% 4.8s\u001b[0K\u001b[1G104.3 MiB [] 2% 4.1s\u001b[0K\u001b[1G104.3 MiB [] 2% 3.7s\u001b[0K\u001b[1G104.3 MiB [] 3% 3.6s\u001b[0K\u001b[1G104.3 MiB [] 4% 2.9s\u001b[0K\u001b[1G104.3 MiB [] 5% 2.7s\u001b[0K\u001b[1G104.3 MiB [] 6% 2.4s\u001b[0K\u001b[1G104.3 MiB [] 7% 2.4s\u001b[0K\u001b[1G104.3 MiB [] 8% 2.5s\u001b[0K\u001b[1G104.3 MiB [] 8% 2.6s\u001b[0K\u001b[1G104.3 MiB [] 8% 2.8s\u001b[0K\u001b[1G104.3 MiB [] 9% 2.7s\u001b[0K\u001b[1G104.3 MiB [] 10% 2.6s\u001b[0K\u001b[1G104.3 MiB [] 11% 2.6s\u001b[0K\u001b[1G104.3 MiB [] 12% 2.5s\u001b[0K\u001b[1G104.3 MiB [] 12% 2.4s\u001b[0K\u001b[1G104.3 MiB [] 13% 2.3s\u001b[0K\u001b[1G104.3 MiB [] 14% 2.2s\u001b[0K\u001b[1G104.3 MiB [] 15% 2.2s\u001b[0K\u001b[1G104.3 MiB [] 16% 2.1s\u001b[0K\u001b[1G104.3 MiB [] 17% 2.0s\u001b[0K\u001b[1G104.3 MiB [] 18% 2.0s\u001b[0K\u001b[1G104.3 MiB [] 19% 2.0s\u001b[0K\u001b[1G104.3 MiB [] 20% 1.9s\u001b[0K\u001b[1G104.3 MiB [] 21% 1.8s\u001b[0K\u001b[1G104.3 MiB [] 22% 1.8s\u001b[0K\u001b[1G104.3 MiB [] 23% 1.7s\u001b[0K\u001b[1G104.3 MiB [] 24% 1.7s\u001b[0K\u001b[1G104.3 MiB [] 25% 1.6s\u001b[0K\u001b[1G104.3 MiB [] 26% 1.6s\u001b[0K\u001b[1G104.3 MiB [] 27% 1.6s\u001b[0K\u001b[1G104.3 MiB [] 28% 1.6s\u001b[0K\u001b[1G104.3 MiB [] 29% 1.5s\u001b[0K\u001b[1G104.3 MiB [] 30% 1.5s\u001b[0K\u001b[1G104.3 MiB [] 31% 1.5s\u001b[0K\u001b[1G104.3 MiB [] 32% 1.5s\u001b[0K\u001b[1G104.3 MiB [] 33% 1.4s\u001b[0K\u001b[1G104.3 MiB [] 35% 1.3s\u001b[0K\u001b[1G104.3 MiB [] 36% 1.3s\u001b[0K\u001b[1G104.3 MiB [] 37% 1.3s\u001b[0K\u001b[1G104.3 MiB [] 37% 1.4s\u001b[0K\u001b[1G104.3 MiB [] 38% 1.4s\u001b[0K\u001b[1G104.3 MiB [] 39% 1.3s\u001b[0K\u001b[1G104.3 MiB [] 40% 1.3s\u001b[0K\u001b[1G104.3 MiB [] 41% 1.3s\u001b[0K\u001b[1G104.3 MiB [] 43% 1.2s\u001b[0K\u001b[1G104.3 MiB [] 44% 1.2s\u001b[0K\u001b[1G104.3 MiB [] 45% 1.2s\u001b[0K\u001b[1G104.3 MiB [] 46% 1.2s\u001b[0K\u001b[1G104.3 MiB [] 48% 1.2s\u001b[0K\u001b[1G104.3 MiB [] 48% 1.1s\u001b[0K\u001b[1G104.3 MiB [] 49% 1.1s\u001b[0K\u001b[1G104.3 MiB [] 50% 1.1s\u001b[0K\u001b[1G104.3 MiB [] 51% 1.1s\u001b[0K\u001b[1G104.3 MiB [] 52% 1.1s\u001b[0K\u001b[1G104.3 MiB [] 53% 1.0s\u001b[0K\u001b[1G104.3 MiB [] 54% 1.0s\u001b[0K\u001b[1G104.3 MiB [] 55% 1.0s\u001b[0K\u001b[1G104.3 MiB [] 56% 1.0s\u001b[0K\u001b[1G104.3 MiB [] 57% 1.0s\u001b[0K\u001b[1G104.3 MiB [] 58% 0.9s\u001b[0K\u001b[1G104.3 MiB [] 59% 0.9s\u001b[0K\u001b[1G104.3 MiB [] 60% 0.9s\u001b[0K\u001b[1G104.3 MiB [] 61% 0.9s\u001b[0K\u001b[1G104.3 MiB [] 62% 0.9s\u001b[0K\u001b[1G104.3 MiB [] 63% 0.8s\u001b[0K\u001b[1G104.3 MiB [] 64% 0.8s\u001b[0K\u001b[1G104.3 MiB [] 65% 0.8s\u001b[0K\u001b[1G104.3 MiB [] 66% 0.8s\u001b[0K\u001b[1G104.3 MiB [] 67% 0.8s\u001b[0K\u001b[1G104.3 MiB [] 68% 0.8s\u001b[0K\u001b[1G104.3 MiB [] 68% 0.7s\u001b[0K\u001b[1G104.3 MiB [] 69% 0.7s\u001b[0K\u001b[1G104.3 MiB [] 70% 0.7s\u001b[0K\u001b[1G104.3 MiB [] 71% 0.7s\u001b[0K\u001b[1G104.3 MiB [] 72% 0.7s\u001b[0K\u001b[1G104.3 MiB [] 73% 0.7s\u001b[0K\u001b[1G104.3 MiB [] 73% 0.6s\u001b[0K\u001b[1G104.3 MiB [] 74% 0.6s\u001b[0K\u001b[1G104.3 MiB [] 75% 0.6s\u001b[0K\u001b[1G104.3 MiB [] 76% 0.6s\u001b[0K\u001b[1G104.3 MiB [] 77% 0.5s\u001b[0K\u001b[1G104.3 MiB [] 78% 0.5s\u001b[0K\u001b[1G104.3 MiB [] 79% 0.5s\u001b[0K\u001b[1G104.3 MiB [] 80% 0.5s\u001b[0K\u001b[1G104.3 MiB [] 81% 0.4s\u001b[0K\u001b[1G104.3 MiB [] 82% 0.4s\u001b[0K\u001b[1G104.3 MiB [] 83% 0.4s\u001b[0K\u001b[1G104.3 MiB [] 84% 0.4s\u001b[0K\u001b[1G104.3 MiB [] 85% 0.3s\u001b[0K\u001b[1G104.3 MiB [] 86% 0.3s\u001b[0K\u001b[1G104.3 MiB [] 88% 0.3s\u001b[0K\u001b[1G104.3 MiB [] 89% 0.2s\u001b[0K\u001b[1G104.3 MiB [] 90% 0.2s\u001b[0K\u001b[1G104.3 MiB [] 91% 0.2s\u001b[0K\u001b[1G104.3 MiB [] 92% 0.2s\u001b[0K\u001b[1G104.3 MiB [] 93% 0.2s\u001b[0K\u001b[1G104.3 MiB [] 93% 0.1s\u001b[0K\u001b[1G104.3 MiB [] 94% 0.1s\u001b[0K\u001b[1G104.3 MiB [] 95% 0.1s\u001b[0K\u001b[1G104.3 MiB [] 96% 0.1s\u001b[0K\u001b[1G104.3 MiB [] 97% 0.1s\u001b[0K\u001b[1G104.3 MiB [] 98% 0.0s\u001b[0K\u001b[1G104.3 MiB [] 99% 0.0s\u001b[0K\u001b[1G104.3 MiB [] 100% 0.0s\u001b[0K\n",
            "Chromium Headless Shell 140.0.7339.16 (playwright build v1187) downloaded to /root/.cache/ms-playwright/chromium_headless_shell-1187\n",
            "Downloading Firefox 141.0 (playwright build v1490)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/firefox/1490/firefox-ubuntu-22.04.zip\u001b[22m\n",
            "\u001b[1G96 MiB [] 0% 0.0s\u001b[0K\u001b[1G96 MiB [] 0% 20.3s\u001b[0K\u001b[1G96 MiB [] 0% 8.5s\u001b[0K\u001b[1G96 MiB [] 1% 5.3s\u001b[0K\u001b[1G96 MiB [] 1% 3.7s\u001b[0K\u001b[1G96 MiB [] 2% 2.9s\u001b[0K\u001b[1G96 MiB [] 4% 2.4s\u001b[0K\u001b[1G96 MiB [] 5% 2.0s\u001b[0K\u001b[1G96 MiB [] 6% 1.8s\u001b[0K\u001b[1G96 MiB [] 8% 1.7s\u001b[0K\u001b[1G96 MiB [] 9% 1.8s\u001b[0K\u001b[1G96 MiB [] 10% 1.7s\u001b[0K\u001b[1G96 MiB [] 11% 1.7s\u001b[0K\u001b[1G96 MiB [] 12% 1.7s\u001b[0K\u001b[1G96 MiB [] 14% 1.6s\u001b[0K\u001b[1G96 MiB [] 15% 1.5s\u001b[0K\u001b[1G96 MiB [] 16% 1.5s\u001b[0K\u001b[1G96 MiB [] 17% 1.5s\u001b[0K\u001b[1G96 MiB [] 18% 1.4s\u001b[0K\u001b[1G96 MiB [] 20% 1.3s\u001b[0K\u001b[1G96 MiB [] 22% 1.2s\u001b[0K\u001b[1G96 MiB [] 23% 1.2s\u001b[0K\u001b[1G96 MiB [] 24% 1.2s\u001b[0K\u001b[1G96 MiB [] 25% 1.2s\u001b[0K\u001b[1G96 MiB [] 27% 1.1s\u001b[0K\u001b[1G96 MiB [] 29% 1.0s\u001b[0K\u001b[1G96 MiB [] 32% 1.0s\u001b[0K\u001b[1G96 MiB [] 34% 0.9s\u001b[0K\u001b[1G96 MiB [] 35% 0.9s\u001b[0K\u001b[1G96 MiB [] 36% 0.9s\u001b[0K\u001b[1G96 MiB [] 37% 0.9s\u001b[0K\u001b[1G96 MiB [] 38% 0.9s\u001b[0K\u001b[1G96 MiB [] 39% 0.8s\u001b[0K\u001b[1G96 MiB [] 41% 0.8s\u001b[0K\u001b[1G96 MiB [] 43% 0.8s\u001b[0K\u001b[1G96 MiB [] 45% 0.7s\u001b[0K\u001b[1G96 MiB [] 46% 0.7s\u001b[0K\u001b[1G96 MiB [] 48% 0.7s\u001b[0K\u001b[1G96 MiB [] 51% 0.6s\u001b[0K\u001b[1G96 MiB [] 53% 0.6s\u001b[0K\u001b[1G96 MiB [] 56% 0.5s\u001b[0K\u001b[1G96 MiB [] 58% 0.5s\u001b[0K\u001b[1G96 MiB [] 60% 0.5s\u001b[0K\u001b[1G96 MiB [] 62% 0.4s\u001b[0K\u001b[1G96 MiB [] 65% 0.4s\u001b[0K\u001b[1G96 MiB [] 68% 0.4s\u001b[0K\u001b[1G96 MiB [] 70% 0.3s\u001b[0K\u001b[1G96 MiB [] 72% 0.3s\u001b[0K\u001b[1G96 MiB [] 74% 0.3s\u001b[0K\u001b[1G96 MiB [] 77% 0.2s\u001b[0K\u001b[1G96 MiB [] 79% 0.2s\u001b[0K\u001b[1G96 MiB [] 82% 0.2s\u001b[0K\u001b[1G96 MiB [] 84% 0.2s\u001b[0K\u001b[1G96 MiB [] 87% 0.1s\u001b[0K\u001b[1G96 MiB [] 89% 0.1s\u001b[0K\u001b[1G96 MiB [] 92% 0.1s\u001b[0K\u001b[1G96 MiB [] 95% 0.0s\u001b[0K\u001b[1G96 MiB [] 97% 0.0s\u001b[0K\u001b[1G96 MiB [] 99% 0.0s\u001b[0K\u001b[1G96 MiB [] 100% 0.0s\u001b[0K\n",
            "Firefox 141.0 (playwright build v1490) downloaded to /root/.cache/ms-playwright/firefox-1490\n",
            "Downloading Webkit 26.0 (playwright build v2203)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/webkit/2203/webkit-ubuntu-22.04.zip\u001b[22m\n",
            "\u001b[1G94.6 MiB [] 0% 0.0s\u001b[0K\u001b[1G94.6 MiB [] 0% 16.8s\u001b[0K\u001b[1G94.6 MiB [] 0% 8.2s\u001b[0K\u001b[1G94.6 MiB [] 1% 4.5s\u001b[0K\u001b[1G94.6 MiB [] 2% 2.7s\u001b[0K\u001b[1G94.6 MiB [] 3% 2.1s\u001b[0K\u001b[1G94.6 MiB [] 5% 1.7s\u001b[0K\u001b[1G94.6 MiB [] 7% 1.5s\u001b[0K\u001b[1G94.6 MiB [] 9% 1.3s\u001b[0K\u001b[1G94.6 MiB [] 9% 1.4s\u001b[0K\u001b[1G94.6 MiB [] 10% 1.4s\u001b[0K\u001b[1G94.6 MiB [] 12% 1.3s\u001b[0K\u001b[1G94.6 MiB [] 13% 1.3s\u001b[0K\u001b[1G94.6 MiB [] 15% 1.2s\u001b[0K\u001b[1G94.6 MiB [] 16% 1.2s\u001b[0K\u001b[1G94.6 MiB [] 17% 1.2s\u001b[0K\u001b[1G94.6 MiB [] 18% 1.1s\u001b[0K\u001b[1G94.6 MiB [] 20% 1.1s\u001b[0K\u001b[1G94.6 MiB [] 23% 1.0s\u001b[0K\u001b[1G94.6 MiB [] 24% 1.0s\u001b[0K\u001b[1G94.6 MiB [] 25% 1.0s\u001b[0K\u001b[1G94.6 MiB [] 27% 0.9s\u001b[0K\u001b[1G94.6 MiB [] 29% 0.8s\u001b[0K\u001b[1G94.6 MiB [] 31% 0.8s\u001b[0K\u001b[1G94.6 MiB [] 34% 0.7s\u001b[0K\u001b[1G94.6 MiB [] 37% 0.7s\u001b[0K\u001b[1G94.6 MiB [] 38% 0.7s\u001b[0K\u001b[1G94.6 MiB [] 41% 0.6s\u001b[0K\u001b[1G94.6 MiB [] 43% 0.6s\u001b[0K\u001b[1G94.6 MiB [] 45% 0.6s\u001b[0K\u001b[1G94.6 MiB [] 48% 0.5s\u001b[0K\u001b[1G94.6 MiB [] 49% 0.5s\u001b[0K\u001b[1G94.6 MiB [] 53% 0.5s\u001b[0K\u001b[1G94.6 MiB [] 54% 0.5s\u001b[0K\u001b[1G94.6 MiB [] 57% 0.4s\u001b[0K\u001b[1G94.6 MiB [] 60% 0.4s\u001b[0K\u001b[1G94.6 MiB [] 64% 0.3s\u001b[0K\u001b[1G94.6 MiB [] 67% 0.3s\u001b[0K\u001b[1G94.6 MiB [] 69% 0.3s\u001b[0K\u001b[1G94.6 MiB [] 71% 0.3s\u001b[0K\u001b[1G94.6 MiB [] 75% 0.2s\u001b[0K\u001b[1G94.6 MiB [] 77% 0.2s\u001b[0K\u001b[1G94.6 MiB [] 78% 0.2s\u001b[0K\u001b[1G94.6 MiB [] 80% 0.2s\u001b[0K\u001b[1G94.6 MiB [] 82% 0.2s\u001b[0K\u001b[1G94.6 MiB [] 83% 0.1s\u001b[0K\u001b[1G94.6 MiB [] 85% 0.1s\u001b[0K\u001b[1G94.6 MiB [] 87% 0.1s\u001b[0K\u001b[1G94.6 MiB [] 89% 0.1s\u001b[0K\u001b[1G94.6 MiB [] 91% 0.1s\u001b[0K\u001b[1G94.6 MiB [] 93% 0.1s\u001b[0K\u001b[1G94.6 MiB [] 94% 0.0s\u001b[0K\u001b[1G94.6 MiB [] 96% 0.0s\u001b[0K\u001b[1G94.6 MiB [] 99% 0.0s\u001b[0K\u001b[1G94.6 MiB [] 100% 0.0s\u001b[0K\n",
            "Webkit 26.0 (playwright build v2203) downloaded to /root/.cache/ms-playwright/webkit-2203\n",
            "Downloading FFMPEG playwright build v1011\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/ffmpeg/1011/ffmpeg-linux.zip\u001b[22m\n",
            "\u001b[1G2.3 MiB [] 0% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 4% 0.4s\u001b[0K\u001b[1G2.3 MiB [] 10% 0.3s\u001b[0K\u001b[1G2.3 MiB [] 35% 0.1s\u001b[0K\u001b[1G2.3 MiB [] 75% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 100% 0.0s\u001b[0K\n",
            "FFMPEG playwright build v1011 downloaded to /root/.cache/ms-playwright/ffmpeg-1011\n",
            "Playwright Host validation warning: \n",
            "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
            "‚ïë Host system is missing dependencies to run browsers. ‚ïë\n",
            "‚ïë Missing libraries:                                   ‚ïë\n",
            "‚ïë     libwoff2dec.so.1.0.2                             ‚ïë\n",
            "‚ïë     libgstgl-1.0.so.0                                ‚ïë\n",
            "‚ïë     libgstcodecparsers-1.0.so.0                      ‚ïë\n",
            "‚ïë     libavif.so.13                                    ‚ïë\n",
            "‚ïë     libharfbuzz-icu.so.0                             ‚ïë\n",
            "‚ïë     libenchant-2.so.2                                ‚ïë\n",
            "‚ïë     libsecret-1.so.0                                 ‚ïë\n",
            "‚ïë     libhyphen.so.0                                   ‚ïë\n",
            "‚ïë     libmanette-0.2.so.0                              ‚ïë\n",
            "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
            "    at validateDependenciesLinux (/usr/local/lib/python3.12/dist-packages/playwright/driver/package/lib/server/registry/dependencies.js:269:9)\n",
            "    at async Registry._validateHostRequirements (/usr/local/lib/python3.12/dist-packages/playwright/driver/package/lib/server/registry/index.js:934:14)\n",
            "    at async Registry._validateHostRequirementsForExecutableIfNeeded (/usr/local/lib/python3.12/dist-packages/playwright/driver/package/lib/server/registry/index.js:1056:7)\n",
            "    at async Registry.validateHostRequirementsForExecutablesIfNeeded (/usr/local/lib/python3.12/dist-packages/playwright/driver/package/lib/server/registry/index.js:1045:7)\n",
            "    at async i.<anonymous> (/usr/local/lib/python3.12/dist-packages/playwright/driver/package/lib/cli/program.js:217:7)\n"
          ]
        }
      ],
      "source": [
        "!pip install playwright\n",
        "!playwright install"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install asyncio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JT_kooZKjvfg",
        "outputId": "ba2b0457-7bab-48c8-eb09-1d503e41e95f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting asyncio\n",
            "  Downloading asyncio-4.0.0-py3-none-any.whl.metadata (994 bytes)\n",
            "Downloading asyncio-4.0.0-py3-none-any.whl (5.6 kB)\n",
            "Installing collected packages: asyncio\n",
            "Successfully installed asyncio-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from playwright.async_api import async_playwright\n",
        "import json\n",
        "import time\n",
        "\n",
        "class MetroLahoreScraper:\n",
        "    def __init__(self, headless=True):\n",
        "        self.headless = headless\n",
        "        self.base_url = \"https://www.metro-online.pk/home\"\n",
        "\n",
        "    async def scroll_to_load_all_products(self, page):\n",
        "        \"\"\"Scroll to bottom multiple times to load all lazy-loaded products\"\"\"\n",
        "        print(\"    Scrolling to load all products...\")\n",
        "        previous_height = 0\n",
        "        scroll_attempts = 0\n",
        "        max_scroll_attempts = 15\n",
        "        no_change_count = 0\n",
        "\n",
        "        while scroll_attempts < max_scroll_attempts:\n",
        "            # Get current scroll height\n",
        "            current_height = await page.evaluate('''() => {\n",
        "                window.scrollTo(0, document.body.scrollHeight);\n",
        "                return document.body.scrollHeight;\n",
        "            }''')\n",
        "\n",
        "            # Wait for content to load\n",
        "            await asyncio.sleep(2)\n",
        "\n",
        "            # Check for load more button\n",
        "            load_more_selectors = [\n",
        "                'button:has-text(\"Load More\")',\n",
        "                'button:has-text(\"Show More\")',\n",
        "                'button:has-text(\"View More\")',\n",
        "                '.load-more',\n",
        "                '.show-more'\n",
        "            ]\n",
        "\n",
        "            for selector in load_more_selectors:\n",
        "                try:\n",
        "                    load_more_btn = await page.query_selector(selector)\n",
        "                    if load_more_btn and await load_more_btn.is_visible():\n",
        "                        await load_more_btn.click()\n",
        "                        await asyncio.sleep(3)\n",
        "                        break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "            # Check if we've reached the bottom\n",
        "            if current_height == previous_height:\n",
        "                no_change_count += 1\n",
        "                if no_change_count >= 2:  # If no change for 2 consecutive scrolls\n",
        "                    break\n",
        "            else:\n",
        "                no_change_count = 0\n",
        "\n",
        "            previous_height = current_height\n",
        "            scroll_attempts += 1\n",
        "\n",
        "            # Check if we have a reasonable number of products loaded\n",
        "            product_count = await page.evaluate('''() => {\n",
        "                return document.querySelectorAll('.CategoryGrid_product_card__FUMXW').length;\n",
        "            }''')\n",
        "\n",
        "            print(f\"    Scroll {scroll_attempts}: Loaded {product_count} products so far...\")\n",
        "\n",
        "        print(f\"    Finished scrolling. Total attempts: {scroll_attempts}\")\n",
        "        return scroll_attempts\n",
        "\n",
        "    async def scrape_main_categories(self, page):\n",
        "        \"\"\"Extract all main categories from homepage\"\"\"\n",
        "        print(\"Step 1: Extracting main categories...\")\n",
        "\n",
        "        await page.wait_for_selector('.CategoryGrid_grid_container__ouyHW', timeout=15000)\n",
        "\n",
        "        main_categories = await page.evaluate('''(base_url) => {\n",
        "            const categories = [];\n",
        "            const categoryElements = document.querySelectorAll('.CategoryGrid_grid_item__FXimL');\n",
        "\n",
        "            categoryElements.forEach((element) => {\n",
        "                const linkElement = element.querySelector('a');\n",
        "                const imgElement = element.querySelector('img');\n",
        "\n",
        "                if (linkElement && imgElement) {\n",
        "                    const category = {\n",
        "                        name: imgElement.alt || 'No name',\n",
        "                        url: linkElement.href || 'No URL',\n",
        "                        image_url: imgElement.src || 'No image',\n",
        "                        sub_categories: []\n",
        "                    };\n",
        "\n",
        "                    categories.push(category);\n",
        "                }\n",
        "            });\n",
        "\n",
        "            return categories;\n",
        "        }''', self.base_url)\n",
        "\n",
        "        print(f\"‚úì Found {len(main_categories)} main categories\")\n",
        "        return main_categories\n",
        "\n",
        "    async def scrape_sub_categories(self, browser, main_categories):\n",
        "        \"\"\"Extract sub-categories for each main category\"\"\"\n",
        "        print(\"\\nStep 2: Extracting sub-categories...\")\n",
        "\n",
        "        all_subcategory_links = []\n",
        "\n",
        "        for i, category in enumerate(main_categories, 1):\n",
        "            print(f\"  Processing category {i}/{len(main_categories)}: {category['name']}\")\n",
        "\n",
        "            try:\n",
        "                category_page = await browser.new_page()\n",
        "\n",
        "                # Build full URL\n",
        "                if category['url'].startswith('/'):\n",
        "                    full_url = f\"{self.base_url}{category['url']}\"\n",
        "                else:\n",
        "                    full_url = category['url']\n",
        "\n",
        "                await category_page.goto(full_url, wait_until='networkidle', timeout=45000)\n",
        "\n",
        "                # Try multiple selectors for sub-categories container\n",
        "                sub_category_selectors = [\n",
        "                    '.sc-gKPRtg.jJzJeK',\n",
        "                ]\n",
        "\n",
        "                sub_categories = []\n",
        "                for selector in sub_category_selectors:\n",
        "                    try:\n",
        "                        await category_page.wait_for_selector(selector, timeout=5000)\n",
        "                        sub_categories = await category_page.evaluate('''(selector) => {\n",
        "                            const subCats = [];\n",
        "                            const container = document.querySelector(selector);\n",
        "\n",
        "                            if (container) {\n",
        "                                const links = container.querySelectorAll('a');\n",
        "                                links.forEach((link) => {\n",
        "                                    const imgElement = link.querySelector('img');\n",
        "                                    const nameElement = link.querySelector('h6, .sc-cwSeag, [class*=\"name\"], [class*=\"title\"]');\n",
        "\n",
        "                                    if (link.href && nameElement) {\n",
        "                                        const subCat = {\n",
        "                                            name: nameElement.textContent?.trim() || 'No name',\n",
        "                                            url: link.href,\n",
        "                                            image_url: imgElement?.src || 'No image',\n",
        "                                            alt_text: imgElement?.alt || 'No alt text'\n",
        "                                        };\n",
        "                                        subCats.push(subCat);\n",
        "                                    }\n",
        "                                });\n",
        "                            }\n",
        "                            return subCats;\n",
        "                        }''', selector)\n",
        "\n",
        "                        if sub_categories:\n",
        "                            break\n",
        "                    except:\n",
        "                        continue\n",
        "\n",
        "                category['sub_categories'] = sub_categories\n",
        "\n",
        "                # Add to master list\n",
        "                for sub_cat in sub_categories:\n",
        "                    all_subcategory_links.append({\n",
        "                        'main_category': category['name'],\n",
        "                        'sub_category': sub_cat['name'],\n",
        "                        'url': sub_cat['url'],\n",
        "                        'image_url': sub_cat['image_url'],\n",
        "                        'main_category_url': category['url']\n",
        "                    })\n",
        "\n",
        "                print(f\"    ‚úì Found {len(sub_categories)} sub-categories\")\n",
        "                await category_page.close()\n",
        "                await asyncio.sleep(1.5)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"    ‚úó Error processing {category['name']}: {str(e)}\")\n",
        "                category['sub_categories'] = []\n",
        "                try:\n",
        "                    await category_page.close()\n",
        "                except:\n",
        "                    pass\n",
        "                continue\n",
        "\n",
        "        total_subcategories = sum(len(cat['sub_categories']) for cat in main_categories)\n",
        "        print(f\"\\n‚úì Total sub-categories found: {total_subcategories}\")\n",
        "        return main_categories, all_subcategory_links\n",
        "\n",
        "    async def scrape_products_from_subcategory(self, page, subcat_link):\n",
        "        \"\"\"Scrape all products from a single sub-category with lazy loading handling\"\"\"\n",
        "        try:\n",
        "            # Build full URL\n",
        "            if subcat_link['url'].startswith('/'):\n",
        "                full_url = f\"{self.base_url}{subcat_link['url']}\"\n",
        "            else:\n",
        "                full_url = subcat_link['url']\n",
        "\n",
        "            await page.goto(full_url, wait_until='networkidle', timeout=45000)\n",
        "\n",
        "            # Wait for initial products\n",
        "            try:\n",
        "                await page.wait_for_selector('.CategoryGrid_product_card__FUMXW', timeout=10000)\n",
        "            except:\n",
        "                return []  # No products found\n",
        "\n",
        "            # Scroll to load all lazy-loaded products\n",
        "            await self.scroll_to_load_all_products(page)\n",
        "\n",
        "            # Final wait to ensure everything is loaded\n",
        "            await asyncio.sleep(2)\n",
        "\n",
        "            # Extract products\n",
        "            products = await page.evaluate('''() => {\n",
        "                const products = [];\n",
        "                const productElements = document.querySelectorAll('.CategoryGrid_product_card__FUMXW');\n",
        "\n",
        "                productElements.forEach((productEl) => {\n",
        "                    // Product name\n",
        "                    const nameElement = productEl.querySelector('.CategoryGrid_product_name__3nYsN');\n",
        "                    const productName = nameElement?.textContent?.trim() || 'No name';\n",
        "\n",
        "                    // Product price\n",
        "                    const priceElement = productEl.querySelector('.CategoryGrid_product_price__Svf8T');\n",
        "                    const productPrice = priceElement?.textContent?.trim() || 'No price';\n",
        "\n",
        "                    // Product URL\n",
        "                    const linkElement = productEl.querySelector('a[href*=\"/detail/\"]');\n",
        "                    const productUrl = linkElement?.href || 'No URL';\n",
        "                    const productPath = linkElement?.getAttribute('href') || 'No path';\n",
        "\n",
        "                    // Product image\n",
        "                    const imgElement = productEl.querySelector('img');\n",
        "                    const productImage = imgElement?.src || 'No image';\n",
        "                    const productAlt = imgElement?.alt || 'No alt text';\n",
        "\n",
        "                    // Badge\n",
        "                    const badgeElement = productEl.querySelector('[data-after-content]');\n",
        "                    const badge = badgeElement?.getAttribute('data-after-content') || null;\n",
        "\n",
        "                    // Product ID from URL\n",
        "                    const urlParts = productUrl.split('/');\n",
        "                    const productId = urlParts[urlParts.length - 1] || 'No ID';\n",
        "\n",
        "                    const product = {\n",
        "                        id: productId,\n",
        "                        name: productName,\n",
        "                        price: productPrice,\n",
        "                        url: productUrl,\n",
        "                        path: productPath,\n",
        "                        image_url: productImage,\n",
        "                        alt_text: productAlt,\n",
        "                        badge: badge,\n",
        "                        scraped_at: new Date().toISOString()\n",
        "                    };\n",
        "\n",
        "                    products.push(product);\n",
        "                });\n",
        "\n",
        "                return products;\n",
        "            }''')\n",
        "\n",
        "            # Add category info\n",
        "            for product in products:\n",
        "                product.update({\n",
        "                    'main_category': subcat_link['main_category'],\n",
        "                    'sub_category': subcat_link['sub_category'],\n",
        "                    'main_category_url': subcat_link['main_category_url'],\n",
        "                    'sub_category_url': subcat_link['url']\n",
        "                })\n",
        "\n",
        "            return products\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"      ‚úó Error scraping products: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    async def scrape_all_products(self, browser, all_subcategory_links, max_subcategories=None):\n",
        "        \"\"\"Scrape products from all sub-categories\"\"\"\n",
        "        print(\"\\nStep 3: Scraping products from sub-categories...\")\n",
        "\n",
        "        if max_subcategories:\n",
        "            all_subcategory_links = all_subcategory_links[:max_subcategories]\n",
        "            print(f\"  Testing mode: Scraping first {max_subcategories} sub-categories\")\n",
        "\n",
        "        all_products = []\n",
        "\n",
        "        for i, subcat_link in enumerate(all_subcategory_links, 1):\n",
        "            print(f\"  Processing sub-category {i}/{len(all_subcategory_links)}: {subcat_link['sub_category']}\")\n",
        "\n",
        "            try:\n",
        "                product_page = await browser.new_page()\n",
        "                products = await self.scrape_products_from_subcategory(product_page, subcat_link)\n",
        "                all_products.extend(products)\n",
        "\n",
        "                print(f\"    ‚úì Found {len(products)} products\")\n",
        "                await product_page.close()\n",
        "                await asyncio.sleep(2)  # Rate limiting\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"    ‚úó Failed to process {subcat_link['sub_category']}: {str(e)}\")\n",
        "                try:\n",
        "                    await product_page.close()\n",
        "                except:\n",
        "                    pass\n",
        "                continue\n",
        "\n",
        "        return all_products\n",
        "\n",
        "    async def run_complete_scraping(self, test_mode=True):\n",
        "        \"\"\"Main function to run complete scraping process\"\"\"\n",
        "        print(\"üöÄ Starting Metro Lahore Complete Scraper\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        async with async_playwright() as p:\n",
        "            browser = await p.chromium.launch(headless=self.headless)\n",
        "\n",
        "            try:\n",
        "                # Step 1: Get main page and categories\n",
        "                main_page = await browser.new_page()\n",
        "                await main_page.goto(self.base_url, wait_until='networkidle', timeout=45000)\n",
        "\n",
        "                main_categories = await self.scrape_main_categories(main_page)\n",
        "                await main_page.close()\n",
        "\n",
        "                if not main_categories:\n",
        "                    print(\"‚ùå No main categories found. Exiting.\")\n",
        "                    return\n",
        "\n",
        "                # Step 2: Get sub-categories\n",
        "                main_categories_with_subs, all_subcategory_links = await self.scrape_sub_categories(browser, main_categories)\n",
        "\n",
        "                if not all_subcategory_links:\n",
        "                    print(\"‚ùå No sub-categories found. Exiting.\")\n",
        "                    return\n",
        "\n",
        "                # Step 3: Get products\n",
        "                if test_mode:\n",
        "                    all_products = await self.scrape_all_products(browser, all_subcategory_links, max_subcategories=1)\n",
        "                else:\n",
        "                    all_products = await self.scrape_all_products(browser, all_subcategory_links)\n",
        "\n",
        "                # Save results\n",
        "                print(f\"\\n\" + \"=\" * 60)\n",
        "                print(\"üíæ Saving results...\")\n",
        "\n",
        "                # Save complete hierarchy\n",
        "                with open('metro_complete_hierarchy.json', 'w', encoding='utf-8') as f:\n",
        "                    json.dump(main_categories_with_subs, f, indent=2, ensure_ascii=False)\n",
        "                print(\"‚úì Saved: metro_complete_hierarchy.json\")\n",
        "\n",
        "                # Save sub-category links\n",
        "                with open('metro_subcategory_links.json', 'w', encoding='utf-8') as f:\n",
        "                    json.dump(all_subcategory_links, f, indent=2, ensure_ascii=False)\n",
        "                print(\"‚úì Saved: metro_subcategory_links.json\")\n",
        "\n",
        "                # Save products\n",
        "                with open('metro_products.json', 'w', encoding='utf-8') as f:\n",
        "                    json.dump(all_products, f, indent=2, ensure_ascii=False)\n",
        "                print(\"‚úì Saved: metro_products.json\")\n",
        "\n",
        "                # Print summary\n",
        "                print(f\"\\nüéâ SCRAPING COMPLETED!\")\n",
        "                print(f\"üìä Summary:\")\n",
        "                print(f\"   ‚Ä¢ Main Categories: {len(main_categories_with_subs)}\")\n",
        "                print(f\"   ‚Ä¢ Sub-categories: {len(all_subcategory_links)}\")\n",
        "                print(f\"   ‚Ä¢ Products: {len(all_products)}\")\n",
        "\n",
        "                if all_products:\n",
        "                    print(f\"\\nüì¶ Sample Products:\")\n",
        "                    for i, product in enumerate(all_products[:5]):\n",
        "                        print(f\"   {i+1}. {product['name']} - {product['price']}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Critical error: {str(e)}\")\n",
        "            finally:\n",
        "                await browser.close()\n",
        "\n",
        "# Usage example\n",
        "async def main():\n",
        "    scraper = MetroLahoreScraper(headless=True)\n",
        "\n",
        "    # For testing (scrapes 2 sub-categories only)\n",
        "    await scraper.run_complete_scraping(test_mode=False)\n",
        "\n",
        "    # For complete scraping (remove test_mode parameter or set to False)\n",
        "    # await scraper.run_complete_scraping(test_mode=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Install required packages first:\n",
        "    # pip install playwright\n",
        "    # playwright install\n",
        "\n",
        "    await main()"
      ],
      "metadata": {
        "id": "Uuz3EHW1djLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from playwright.async_api import async_playwright\n",
        "import json\n",
        "import csv\n",
        "import time\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "class MetroLahoreScraper:\n",
        "    def __init__(self, headless=True):\n",
        "        self.headless = headless\n",
        "        self.base_url = \"https://www.metro-online.pk/home\"\n",
        "\n",
        "    async def scroll_to_load_all_products(self, page):\n",
        "        \"\"\"Scroll to bottom multiple times to load all lazy-loaded products\"\"\"\n",
        "        print(\"    Scrolling to load all products...\")\n",
        "        previous_height = 0\n",
        "        scroll_attempts = 0\n",
        "        max_scroll_attempts = 15\n",
        "        no_change_count = 0\n",
        "\n",
        "        while scroll_attempts < max_scroll_attempts:\n",
        "            # Get current scroll height\n",
        "            current_height = await page.evaluate('''() => {\n",
        "                window.scrollTo(0, document.body.scrollHeight);\n",
        "                return document.body.scrollHeight;\n",
        "            }''')\n",
        "\n",
        "            # Wait for content to load\n",
        "            await asyncio.sleep(2)\n",
        "\n",
        "            # Check for load more button\n",
        "            load_more_selectors = [\n",
        "                'button:has-text(\"Load More\")',\n",
        "                'button:has-text(\"Show More\")',\n",
        "                'button:has-text(\"View More\")',\n",
        "                '.load-more',\n",
        "                '.show-more'\n",
        "            ]\n",
        "\n",
        "            for selector in load_more_selectors:\n",
        "                try:\n",
        "                    load_more_btn = await page.query_selector(selector)\n",
        "                    if load_more_btn and await load_more_btn.is_visible():\n",
        "                        await load_more_btn.click()\n",
        "                        await asyncio.sleep(3)\n",
        "                        break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "            # Check if we've reached the bottom\n",
        "            if current_height == previous_height:\n",
        "                no_change_count += 1\n",
        "                if no_change_count >= 2:  # If no change for 2 consecutive scrolls\n",
        "                    break\n",
        "            else:\n",
        "                no_change_count = 0\n",
        "\n",
        "            previous_height = current_height\n",
        "            scroll_attempts += 1\n",
        "\n",
        "            # Check if we have a reasonable number of products loaded\n",
        "            product_count = await page.evaluate('''() => {\n",
        "                return document.querySelectorAll('.CategoryGrid_product_card__FUMXW').length;\n",
        "            }''')\n",
        "\n",
        "            print(f\"    Scroll {scroll_attempts}: Loaded {product_count} products so far...\")\n",
        "\n",
        "        print(f\"    Finished scrolling. Total attempts: {scroll_attempts}\")\n",
        "        return scroll_attempts\n",
        "\n",
        "    async def scrape_main_categories(self, page):\n",
        "        \"\"\"Extract all main categories from homepage\"\"\"\n",
        "        print(\"Step 1: Extracting main categories...\")\n",
        "\n",
        "        await page.wait_for_selector('.CategoryGrid_grid_container__ouyHW', timeout=15000)\n",
        "\n",
        "        main_categories = await page.evaluate('''(base_url) => {\n",
        "            const categories = [];\n",
        "            const categoryElements = document.querySelectorAll('.CategoryGrid_grid_item__FXimL');\n",
        "\n",
        "            categoryElements.forEach((element) => {\n",
        "                const linkElement = element.querySelector('a');\n",
        "                const imgElement = element.querySelector('img');\n",
        "                const parentDiv = element.closest('[style*=\"position: relative\"]');\n",
        "                const discountElement = parentDiv ? parentDiv.querySelector('.CategoryGrid_smart_tiles_discounted_div__JZLJL') : null;\n",
        "\n",
        "                if (linkElement && imgElement) {\n",
        "                    const category = {\n",
        "                        name: imgElement.alt || 'No name',\n",
        "                        url: linkElement.href || 'No URL',\n",
        "                        image_url: imgElement.src || 'No image',\n",
        "                        discount: null,\n",
        "                        sub_categories: []\n",
        "                    };\n",
        "\n",
        "                    if (discountElement) {\n",
        "                        const discountText = discountElement.querySelector('.CategoryGrid_smart_tiles_discounted_text__txzlQ');\n",
        "                        if (discountText) {\n",
        "                            category.discount = discountText.textContent?.replace('\\\\n', '').trim() + '%' || 'No discount';\n",
        "                        }\n",
        "                    }\n",
        "\n",
        "                    categories.push(category);\n",
        "                }\n",
        "            });\n",
        "\n",
        "            return categories;\n",
        "        }''', self.base_url)\n",
        "\n",
        "        print(f\"‚úì Found {len(main_categories)} main categories\")\n",
        "        return main_categories\n",
        "\n",
        "    async def scrape_sub_categories(self, browser, main_categories):\n",
        "        \"\"\"Extract sub-categories for each main category\"\"\"\n",
        "        print(\"\\nStep 2: Extracting sub-categories...\")\n",
        "\n",
        "        all_subcategory_links = []\n",
        "\n",
        "        for i, category in enumerate(main_categories, 1):\n",
        "            print(f\"  Processing category {i}/{len(main_categories)}: {category['name']}\")\n",
        "\n",
        "            try:\n",
        "                category_page = await browser.new_page()\n",
        "\n",
        "                # Build full URL\n",
        "                if category['url'].startswith('/'):\n",
        "                    full_url = f\"{self.base_url}{category['url']}\"\n",
        "                else:\n",
        "                    full_url = category['url']\n",
        "\n",
        "                await category_page.goto(full_url, wait_until='networkidle', timeout=45000)\n",
        "\n",
        "                # Try multiple selectors for sub-categories container\n",
        "                sub_category_selectors = [\n",
        "                    '.sc-gKPRtg.jJzJeK',\n",
        "\n",
        "                ]\n",
        "\n",
        "                sub_categories = []\n",
        "                for selector in sub_category_selectors:\n",
        "                    try:\n",
        "                        await category_page.wait_for_selector(selector, timeout=5000)\n",
        "                        sub_categories = await category_page.evaluate('''(selector) => {\n",
        "                            const subCats = [];\n",
        "                            const container = document.querySelector(selector);\n",
        "\n",
        "                            if (container) {\n",
        "                                const links = container.querySelectorAll('a');\n",
        "                                links.forEach((link) => {\n",
        "                                    const imgElement = link.querySelector('img');\n",
        "                                    const nameElement = link.querySelector('h6, .sc-cwSeag, [class*=\"name\"], [class*=\"title\"]');\n",
        "\n",
        "                                    if (link.href && nameElement) {\n",
        "                                        const subCat = {\n",
        "                                            name: nameElement.textContent?.trim() || 'No name',\n",
        "                                            url: link.href,\n",
        "                                            image_url: imgElement?.src || 'No image',\n",
        "                                            alt_text: imgElement?.alt || 'No alt text'\n",
        "                                        };\n",
        "                                        subCats.push(subCat);\n",
        "                                    }\n",
        "                                });\n",
        "                            }\n",
        "                            return subCats;\n",
        "                        }''', selector)\n",
        "\n",
        "                        if sub_categories:\n",
        "                            break\n",
        "                    except:\n",
        "                        continue\n",
        "\n",
        "                category['sub_categories'] = sub_categories\n",
        "\n",
        "                # Add to master list\n",
        "                for sub_cat in sub_categories:\n",
        "                    all_subcategory_links.append({\n",
        "                        'main_category': category['name'],\n",
        "                        'sub_category': sub_cat['name'],\n",
        "                        'url': sub_cat['url'],\n",
        "                        'image_url': sub_cat['image_url'],\n",
        "                        'main_category_url': category['url']\n",
        "                    })\n",
        "\n",
        "                print(f\"    ‚úì Found {len(sub_categories)} sub-categories\")\n",
        "                await category_page.close()\n",
        "                await asyncio.sleep(1.5)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"    ‚úó Error processing {category['name']}: {str(e)}\")\n",
        "                category['sub_categories'] = []\n",
        "                try:\n",
        "                    await category_page.close()\n",
        "                except:\n",
        "                    pass\n",
        "                continue\n",
        "\n",
        "        total_subcategories = sum(len(cat['sub_categories']) for cat in main_categories)\n",
        "        print(f\"\\n‚úì Total sub-categories found: {total_subcategories}\")\n",
        "        return main_categories, all_subcategory_links\n",
        "\n",
        "    async def scrape_products_from_subcategory(self, page, subcat_link):\n",
        "        \"\"\"Scrape all products from a single sub-category with lazy loading handling\"\"\"\n",
        "        try:\n",
        "            # Build full URL\n",
        "            if subcat_link['url'].startswith('/'):\n",
        "                full_url = f\"{self.base_url}{subcat_link['url']}\"\n",
        "            else:\n",
        "                full_url = subcat_link['url']\n",
        "\n",
        "            await page.goto(full_url, wait_until='networkidle', timeout=45000)\n",
        "\n",
        "            # Wait for initial products\n",
        "            try:\n",
        "                await page.wait_for_selector('.CategoryGrid_product_card__FUMXW', timeout=10000)\n",
        "            except:\n",
        "                return []  # No products found\n",
        "\n",
        "            # Scroll to load all lazy-loaded products\n",
        "            await self.scroll_to_load_all_products(page)\n",
        "\n",
        "            # Final wait to ensure everything is loaded\n",
        "            await asyncio.sleep(2)\n",
        "\n",
        "            # Extract products\n",
        "            products = await page.evaluate('''() => {\n",
        "                const products = [];\n",
        "                const productElements = document.querySelectorAll('.CategoryGrid_product_card__FUMXW');\n",
        "\n",
        "                productElements.forEach((productEl) => {\n",
        "                    // Product name\n",
        "                    const nameElement = productEl.querySelector('.CategoryGrid_product_name__3nYsN');\n",
        "                    const productName = nameElement?.textContent?.trim() || 'No name';\n",
        "\n",
        "                    // Product price\n",
        "                    const priceElement = productEl.querySelector('.CategoryGrid_product_price__Svf8T');\n",
        "                    const productPrice = priceElement?.textContent?.trim() || 'No price';\n",
        "\n",
        "                    // Product URL\n",
        "                    const linkElement = productEl.querySelector('a[href*=\"/detail/\"]');\n",
        "                    const productUrl = linkElement?.href || 'No URL';\n",
        "                    const productPath = linkElement?.getAttribute('href') || 'No path';\n",
        "\n",
        "                    // Product image\n",
        "                    const imgElement = productEl.querySelector('img');\n",
        "                    const productImage = imgElement?.src || 'No image';\n",
        "                    const productAlt = imgElement?.alt || 'No alt text';\n",
        "\n",
        "                    // Badge\n",
        "                    const badgeElement = productEl.querySelector('[data-after-content]');\n",
        "                    const badge = badgeElement?.getAttribute('data-after-content') || null;\n",
        "\n",
        "                    // Product ID from URL\n",
        "                    const urlParts = productUrl.split('/');\n",
        "                    const productId = urlParts[urlParts.length - 1] || 'No ID';\n",
        "\n",
        "                    const product = {\n",
        "                        id: productId,\n",
        "                        name: productName,\n",
        "                        price: productPrice,\n",
        "                        url: productUrl,\n",
        "                        path: productPath,\n",
        "                        image_url: productImage,\n",
        "                        alt_text: productAlt,\n",
        "                        badge: badge,\n",
        "                        scraped_at: new Date().toISOString()\n",
        "                    };\n",
        "\n",
        "                    products.push(product);\n",
        "                });\n",
        "\n",
        "                return products;\n",
        "            }''')\n",
        "\n",
        "            # Add category info\n",
        "            for product in products:\n",
        "                product.update({\n",
        "                    'main_category': subcat_link['main_category'],\n",
        "                    'sub_category': subcat_link['sub_category'],\n",
        "                    'main_category_url': subcat_link['main_category_url'],\n",
        "                    'sub_category_url': subcat_link['url']\n",
        "                })\n",
        "\n",
        "            return products\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"      ‚úó Error scraping products: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    async def scrape_all_products(self, browser, all_subcategory_links, max_subcategories=None):\n",
        "        \"\"\"Scrape products from all sub-categories\"\"\"\n",
        "        print(\"\\nStep 3: Scraping products from sub-categories...\")\n",
        "\n",
        "        if max_subcategories:\n",
        "            all_subcategory_links = all_subcategory_links[:max_subcategories]\n",
        "            print(f\"  Testing mode: Scraping first {max_subcategories} sub-categories\")\n",
        "\n",
        "        all_products = []\n",
        "\n",
        "        for i, subcat_link in enumerate(all_subcategory_links, 1):\n",
        "            print(f\"  Processing sub-category {i}/{len(all_subcategory_links)}: {subcat_link['sub_category']}\")\n",
        "\n",
        "            try:\n",
        "                product_page = await browser.new_page()\n",
        "\n",
        "                products = await self.scrape_products_from_subcategory(product_page, subcat_link)\n",
        "                all_products.extend(products)\n",
        "\n",
        "                print(f\"    ‚úì Found {len(products)} products\")\n",
        "                await product_page.close()\n",
        "                await asyncio.sleep(2)  # Rate limiting\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"    ‚úó Failed to process {subcat_link['sub_category']}: {str(e)}\")\n",
        "                try:\n",
        "                    await product_page.close()\n",
        "                except:\n",
        "                    pass\n",
        "                continue\n",
        "\n",
        "        return all_products\n",
        "\n",
        "    def save_products_to_csv(self, products, filename=None):\n",
        "        \"\"\"Save products data to CSV file\"\"\"\n",
        "        if not filename:\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f'metro_products_{timestamp}.csv'\n",
        "\n",
        "        # Define CSV fieldnames\n",
        "        fieldnames = [\n",
        "            'id',\n",
        "            'name',\n",
        "            'price',\n",
        "            'main_category',\n",
        "            'sub_category',\n",
        "            'url',\n",
        "            'path',\n",
        "            'image_url',\n",
        "            'alt_text',\n",
        "            'badge',\n",
        "            'main_category_url',\n",
        "            'sub_category_url',\n",
        "            'scraped_at'\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "                writer.writeheader()\n",
        "\n",
        "                for product in products:\n",
        "                    # Clean data for CSV\n",
        "                    cleaned_product = {}\n",
        "                    for field in fieldnames:\n",
        "                        value = product.get(field, '')\n",
        "                        # Handle None values and convert to empty string\n",
        "                        if value is None:\n",
        "                            value = ''\n",
        "                        # Ensure string values are properly encoded\n",
        "                        elif isinstance(value, str):\n",
        "                            value = value.replace('\\n', ' ').replace('\\r', ' ').strip()\n",
        "                        cleaned_product[field] = value\n",
        "\n",
        "                    writer.writerow(cleaned_product)\n",
        "\n",
        "            print(f\"‚úì Products saved to: {filename}\")\n",
        "            return filename\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚úó Error saving CSV: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def save_products_to_json(self, products, filename=None):\n",
        "        \"\"\"Save products data to JSON file (for backup)\"\"\"\n",
        "        if not filename:\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f'metro_products_{timestamp}.json'\n",
        "\n",
        "        try:\n",
        "            with open(filename, 'w', encoding='utf-8') as f:\n",
        "                json.dump(products, f, indent=2, ensure_ascii=False)\n",
        "            print(f\"‚úì JSON backup saved to: {filename}\")\n",
        "            return filename\n",
        "        except Exception as e:\n",
        "            print(f\"‚úó Error saving JSON: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    async def run_complete_scraping(self, test_mode=True):\n",
        "        \"\"\"Main function to run complete scraping process\"\"\"\n",
        "        print(\"üöÄ Starting Metro Lahore Complete Scraper\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        async with async_playwright() as p:\n",
        "            browser = await p.chromium.launch(headless=self.headless)\n",
        "\n",
        "            try:\n",
        "                # Step 1: Get main page and categories\n",
        "                main_page = await browser.new_page()\n",
        "                await main_page.goto(self.base_url, wait_until='networkidle', timeout=45000)\n",
        "\n",
        "                main_categories = await self.scrape_main_categories(main_page)\n",
        "                await main_page.close()\n",
        "\n",
        "                if not main_categories:\n",
        "                    print(\"‚ùå No main categories found. Exiting.\")\n",
        "                    return\n",
        "\n",
        "                # Step 2: Get sub-categories\n",
        "                main_categories_with_subs, all_subcategory_links = await self.scrape_sub_categories(browser, main_categories)\n",
        "\n",
        "                if not all_subcategory_links:\n",
        "                    print(\"‚ùå No sub-categories found. Exiting.\")\n",
        "                    return\n",
        "\n",
        "                # Step 3: Get products\n",
        "                if test_mode:\n",
        "                    all_products = await self.scrape_all_products(browser, all_subcategory_links, max_subcategories=2)\n",
        "                else:\n",
        "                    all_products = await self.scrape_all_products(browser, all_subcategory_links)\n",
        "\n",
        "                # Save results\n",
        "                print(f\"\\n\" + \"=\" * 60)\n",
        "                print(\"üíæ Saving results...\")\n",
        "\n",
        "                # Save complete hierarchy to JSON\n",
        "                with open('metro_complete_hierarchy.json', 'w', encoding='utf-8') as f:\n",
        "                    json.dump(main_categories_with_subs, f, indent=2, ensure_ascii=False)\n",
        "                print(\"‚úì Saved: metro_complete_hierarchy.json\")\n",
        "\n",
        "                # Save sub-category links to JSON\n",
        "                with open('metro_subcategory_links.json', 'w', encoding='utf-8') as f:\n",
        "                    json.dump(all_subcategory_links, f, indent=2, ensure_ascii=False)\n",
        "                print(\"‚úì Saved: metro_subcategory_links.json\")\n",
        "\n",
        "                # Save products to CSV (main output)\n",
        "                csv_filename = self.save_products_to_csv(all_products)\n",
        "\n",
        "                # Save products to JSON (backup)\n",
        "                json_filename = self.save_products_to_json(all_products)\n",
        "\n",
        "                # Print summary\n",
        "                print(f\"\\nüéâ SCRAPING COMPLETED!\")\n",
        "                print(f\"üìä Summary:\")\n",
        "                print(f\"   ‚Ä¢ Main Categories: {len(main_categories_with_subs)}\")\n",
        "                print(f\"   ‚Ä¢ Sub-categories: {len(all_subcategory_links)}\")\n",
        "                print(f\"   ‚Ä¢ Products: {len(all_products)}\")\n",
        "                print(f\"   ‚Ä¢ CSV File: {csv_filename}\")\n",
        "                print(f\"   ‚Ä¢ JSON Backup: {json_filename}\")\n",
        "\n",
        "                if all_products:\n",
        "                    print(f\"\\nüì¶ Sample Products (first 5):\")\n",
        "                    for i, product in enumerate(all_products[:5]):\n",
        "                        print(f\"   {i+1}. {product['name']} - {product['price']}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Critical error: {str(e)}\")\n",
        "            finally:\n",
        "                await browser.close()\n",
        "\n",
        "# Usage example\n",
        "async def main():\n",
        "    scraper = MetroLahoreScraper(headless=True)\n",
        "\n",
        "    # For testing (scrapes 2 sub-categories only)\n",
        "    await scraper.run_complete_scraping(test_mode=False)\n",
        "\n",
        "    # For complete scraping (remove test_mode parameter or set to False)\n",
        "    # await scraper.run_complete_scraping(test_mode=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Install required packages first:\n",
        "    # pip install playwright csv\n",
        "    # playwright install\n",
        "\n",
        "    await main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmYCAFLotOSb",
        "outputId": "9ccc12f1-263c-47e2-d4a8-7839b8ba30d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting Metro Lahore Complete Scraper\n",
            "============================================================\n",
            "Step 1: Extracting main categories...\n",
            "‚úì Found 12 main categories\n",
            "\n",
            "Step 2: Extracting sub-categories...\n",
            "  Processing category 1/12: Metro Post Grocery\n",
            "    ‚úì Found 0 sub-categories\n",
            "  Processing category 2/12: Fruits And Vegetables\n",
            "    ‚úì Found 3 sub-categories\n",
            "  Processing category 3/12: Meat\n",
            "    ‚úì Found 3 sub-categories\n",
            "  Processing category 4/12: Tea and Coffee\n",
            "    ‚úì Found 2 sub-categories\n",
            "  Processing category 5/12: Commodities\n",
            "    ‚úì Found 5 sub-categories\n",
            "  Processing category 6/12: Beverages\n",
            "    ‚úì Found 6 sub-categories\n",
            "  Processing category 7/12: Dairy\n",
            "    ‚úì Found 6 sub-categories\n",
            "  Processing category 8/12: Snacks\n",
            "    ‚úì Found 5 sub-categories\n",
            "  Processing category 9/12: Toiletries\n",
            "    ‚úì Found 2 sub-categories\n",
            "  Processing category 10/12: Frozen Ready to Cook\n",
            "    ‚úì Found 4 sub-categories\n",
            "  Processing category 11/12: Laundry\n",
            "    ‚úì Found 3 sub-categories\n",
            "  Processing category 12/12: Toiletries\n",
            "    ‚úì Found 2 sub-categories\n",
            "\n",
            "‚úì Total sub-categories found: 41\n",
            "\n",
            "Step 3: Scraping products from sub-categories...\n",
            "  Processing sub-category 1/41: Fresh Vegetables\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 24 products so far...\n",
            "    Scroll 2: Loaded 36 products so far...\n",
            "    Scroll 3: Loaded 41 products so far...\n",
            "    Scroll 4: Loaded 41 products so far...\n",
            "    Scroll 5: Loaded 41 products so far...\n",
            "    Finished scrolling. Total attempts: 5\n",
            "    ‚úì Found 41 products\n",
            "  Processing sub-category 2/41: Fresh Fruits\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 21 products so far...\n",
            "    Scroll 2: Loaded 21 products so far...\n",
            "    Scroll 3: Loaded 21 products so far...\n",
            "    Scroll 4: Loaded 21 products so far...\n",
            "    Finished scrolling. Total attempts: 4\n",
            "    ‚úì Found 21 products\n",
            "  Processing sub-category 3/41: Dry Fruits and Nuts\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 36 products so far...\n",
            "    Scroll 2: Loaded 48 products so far...\n",
            "    Scroll 3: Loaded 60 products so far...\n",
            "    Scroll 4: Loaded 66 products so far...\n",
            "    Scroll 5: Loaded 69 products so far...\n",
            "    Scroll 6: Loaded 69 products so far...\n",
            "    Scroll 7: Loaded 69 products so far...\n",
            "    Finished scrolling. Total attempts: 7\n",
            "    ‚úì Found 69 products\n",
            "  Processing sub-category 4/41: Chicken\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 10 products so far...\n",
            "    Scroll 2: Loaded 10 products so far...\n",
            "    Finished scrolling. Total attempts: 2\n",
            "    ‚úì Found 10 products\n",
            "  Processing sub-category 5/41: Beef\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 15 products so far...\n",
            "    Scroll 2: Loaded 15 products so far...\n",
            "    Scroll 3: Loaded 15 products so far...\n",
            "    Finished scrolling. Total attempts: 3\n",
            "    ‚úì Found 15 products\n",
            "  Processing sub-category 6/41: Mutton\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 13 products so far...\n",
            "    Scroll 2: Loaded 13 products so far...\n",
            "    Scroll 3: Loaded 13 products so far...\n",
            "    Finished scrolling. Total attempts: 3\n",
            "    ‚úì Found 13 products\n",
            "  Processing sub-category 7/41: Tea\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 36 products so far...\n",
            "    Scroll 2: Loaded 47 products so far...\n",
            "    Scroll 3: Loaded 59 products so far...\n",
            "    Scroll 4: Loaded 71 products so far...\n",
            "    Scroll 5: Loaded 77 products so far...\n",
            "    Scroll 6: Loaded 77 products so far...\n",
            "    Scroll 7: Loaded 77 products so far...\n",
            "    Finished scrolling. Total attempts: 7\n",
            "    ‚úì Found 77 products\n",
            "  Processing sub-category 8/41: Coffee and Whiteners\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 21 products so far...\n",
            "    Scroll 2: Loaded 21 products so far...\n",
            "    Scroll 3: Loaded 21 products so far...\n",
            "    Finished scrolling. Total attempts: 3\n",
            "    ‚úì Found 21 products\n",
            "  Processing sub-category 9/41: Oil and Ghee\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 24 products so far...\n",
            "    Scroll 2: Loaded 24 products so far...\n",
            "    Scroll 3: Loaded 24 products so far...\n",
            "    Finished scrolling. Total attempts: 3\n",
            "    ‚úì Found 24 products\n",
            "  Processing sub-category 10/41: Flour\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 32 products so far...\n",
            "    Scroll 2: Loaded 37 products so far...\n",
            "    Scroll 3: Loaded 37 products so far...\n",
            "    Scroll 4: Loaded 37 products so far...\n",
            "    Finished scrolling. Total attempts: 4\n",
            "    ‚úì Found 37 products\n",
            "  Processing sub-category 11/41: Sugar\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 15 products so far...\n",
            "    Scroll 2: Loaded 15 products so far...\n",
            "    Scroll 3: Loaded 15 products so far...\n",
            "    Finished scrolling. Total attempts: 3\n",
            "    ‚úì Found 15 products\n",
            "  Processing sub-category 12/41: Pulses\n",
            "    ‚úì Found 0 products\n",
            "  Processing sub-category 13/41: Rice\n",
            "    ‚úì Found 0 products\n",
            "  Processing sub-category 14/41: Soft Drinks\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 24 products so far...\n",
            "    Scroll 2: Loaded 36 products so far...\n",
            "    Scroll 3: Loaded 48 products so far...\n",
            "    Scroll 4: Loaded 60 products so far...\n",
            "    Scroll 5: Loaded 72 products so far...\n",
            "    Scroll 6: Loaded 77 products so far...\n",
            "    Scroll 7: Loaded 88 products so far...\n",
            "    Scroll 8: Loaded 88 products so far...\n",
            "    Scroll 9: Loaded 88 products so far...\n",
            "    Finished scrolling. Total attempts: 9\n",
            "    ‚úì Found 88 products\n",
            "  Processing sub-category 15/41: Juices\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 24 products so far...\n",
            "    Scroll 2: Loaded 36 products so far...\n",
            "    Scroll 3: Loaded 48 products so far...\n",
            "    Scroll 4: Loaded 60 products so far...\n",
            "    Scroll 5: Loaded 72 products so far...\n",
            "    Scroll 6: Loaded 87 products so far...\n",
            "    Scroll 7: Loaded 92 products so far...\n",
            "    Scroll 8: Loaded 92 products so far...\n",
            "    Scroll 9: Loaded 92 products so far...\n",
            "    Finished scrolling. Total attempts: 9\n",
            "    ‚úì Found 92 products\n",
            "  Processing sub-category 16/41: Red Syrups and Squashes\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 12 products so far...\n",
            "    Scroll 2: Loaded 12 products so far...\n",
            "    Scroll 3: Loaded 12 products so far...\n",
            "    Finished scrolling. Total attempts: 3\n",
            "    ‚úì Found 12 products\n",
            "  Processing sub-category 17/41: Powder Drinks\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 12 products so far...\n",
            "    Scroll 2: Loaded 12 products so far...\n",
            "    Scroll 3: Loaded 12 products so far...\n",
            "    Finished scrolling. Total attempts: 3\n",
            "    ‚úì Found 12 products\n",
            "  Processing sub-category 18/41: Water\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 16 products so far...\n",
            "    Scroll 2: Loaded 16 products so far...\n",
            "    Scroll 3: Loaded 16 products so far...\n",
            "    Finished scrolling. Total attempts: 3\n",
            "    ‚úì Found 16 products\n",
            "  Processing sub-category 19/41: Iced Tea and Coffee\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 9 products so far...\n",
            "    Scroll 2: Loaded 9 products so far...\n",
            "    Scroll 3: Loaded 9 products so far...\n",
            "    Finished scrolling. Total attempts: 3\n",
            "    ‚úì Found 9 products\n",
            "  Processing sub-category 20/41: Milk\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 18 products so far...\n",
            "    Scroll 2: Loaded 18 products so far...\n",
            "    Scroll 3: Loaded 18 products so far...\n",
            "    Finished scrolling. Total attempts: 3\n",
            "    ‚úì Found 18 products\n",
            "  Processing sub-category 21/41: Cheese and Cream\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 12 products so far...\n",
            "    Scroll 2: Loaded 12 products so far...\n",
            "    Scroll 3: Loaded 12 products so far...\n",
            "    Finished scrolling. Total attempts: 3\n",
            "    ‚úì Found 12 products\n",
            "  Processing sub-category 22/41: Eggs\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 6 products so far...\n",
            "    Scroll 2: Loaded 6 products so far...\n",
            "    Scroll 3: Loaded 6 products so far...\n",
            "    Finished scrolling. Total attempts: 3\n",
            "    ‚úì Found 6 products\n",
            "  Processing sub-category 23/41: Breakfast\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 12 products so far...\n",
            "    Scroll 2: Loaded 12 products so far...\n",
            "    Scroll 3: Loaded 12 products so far...\n",
            "    Finished scrolling. Total attempts: 3\n",
            "    ‚úì Found 12 products\n",
            "  Processing sub-category 24/41: Butter and Margarine\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 12 products so far...\n",
            "    Scroll 2: Loaded 12 products so far...\n",
            "    Scroll 3: Loaded 12 products so far...\n",
            "    Finished scrolling. Total attempts: 3\n",
            "    ‚úì Found 12 products\n",
            "  Processing sub-category 25/41: Yogurt\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 15 products so far...\n",
            "    Scroll 2: Loaded 15 products so far...\n",
            "    Scroll 3: Loaded 15 products so far...\n",
            "    Finished scrolling. Total attempts: 3\n",
            "    ‚úì Found 15 products\n",
            "  Processing sub-category 26/41: Biscuits And Wafers\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 9 products so far...\n",
            "    Scroll 2: Loaded 9 products so far...\n",
            "    Scroll 3: Loaded 9 products so far...\n",
            "    Finished scrolling. Total attempts: 3\n",
            "    ‚úì Found 9 products\n",
            "  Processing sub-category 27/41: Crisps and Popcorn\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 12 products so far...\n",
            "    Scroll 2: Loaded 12 products so far...\n",
            "    Scroll 3: Loaded 12 products so far...\n",
            "    Finished scrolling. Total attempts: 3\n",
            "    ‚úì Found 12 products\n",
            "  Processing sub-category 28/41: Cakes and Chocolates\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 37 products so far...\n",
            "    Scroll 2: Loaded 49 products so far...\n",
            "    Scroll 3: Loaded 53 products so far...\n",
            "    Scroll 4: Loaded 53 products so far...\n",
            "    Scroll 5: Loaded 53 products so far...\n",
            "    Finished scrolling. Total attempts: 5\n",
            "    ‚úì Found 53 products\n",
            "  Processing sub-category 29/41: Sweets and Toffees\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 30 products so far...\n",
            "    Scroll 2: Loaded 30 products so far...\n",
            "    Scroll 3: Loaded 30 products so far...\n",
            "    Finished scrolling. Total attempts: 3\n",
            "    ‚úì Found 30 products\n",
            "  Processing sub-category 30/41: Jellies and Marshmallows\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 6 products so far...\n",
            "    Scroll 2: Loaded 6 products so far...\n",
            "    Finished scrolling. Total attempts: 2\n",
            "    ‚úì Found 6 products\n",
            "  Processing sub-category 31/41: Women Care\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 24 products so far...\n",
            "    Scroll 2: Loaded 36 products so far...\n",
            "    Scroll 3: Loaded 48 products so far...\n",
            "    Scroll 4: Loaded 62 products so far...\n",
            "    Scroll 5: Loaded 64 products so far...\n",
            "    Scroll 6: Loaded 64 products so far...\n",
            "    Scroll 7: Loaded 64 products so far...\n",
            "    Finished scrolling. Total attempts: 7\n",
            "    ‚úì Found 64 products\n",
            "  Processing sub-category 32/41: Men Grooming\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 24 products so far...\n",
            "    Scroll 2: Loaded 29 products so far...\n",
            "    Scroll 3: Loaded 41 products so far...\n",
            "    Scroll 4: Loaded 49 products so far...\n",
            "    Scroll 5: Loaded 49 products so far...\n",
            "    Scroll 6: Loaded 49 products so far...\n",
            "    Finished scrolling. Total attempts: 6\n",
            "    ‚úì Found 49 products\n",
            "  Processing sub-category 33/41: Nuggets and Snacks\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 24 products so far...\n",
            "    Scroll 2: Loaded 36 products so far...\n",
            "    Scroll 3: Loaded 48 products so far...\n",
            "    Scroll 4: Loaded 60 products so far...\n",
            "    Scroll 5: Loaded 72 products so far...\n",
            "    Scroll 6: Loaded 84 products so far...\n",
            "    Scroll 7: Loaded 96 products so far...\n",
            "    Scroll 8: Loaded 104 products so far...\n",
            "    Scroll 9: Loaded 115 products so far...\n",
            "    Scroll 10: Loaded 115 products so far...\n",
            "    Scroll 11: Loaded 115 products so far...\n",
            "    Finished scrolling. Total attempts: 11\n",
            "    ‚úì Found 115 products\n",
            "  Processing sub-category 34/41: Kebab and Koftas\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 24 products so far...\n",
            "    Scroll 2: Loaded 36 products so far...\n",
            "    Scroll 3: Loaded 48 products so far...\n",
            "    Scroll 4: Loaded 56 products so far...\n",
            "    Scroll 5: Loaded 67 products so far...\n",
            "    Scroll 6: Loaded 67 products so far...\n",
            "    Scroll 7: Loaded 67 products so far...\n",
            "    Finished scrolling. Total attempts: 7\n",
            "    ‚úì Found 67 products\n",
            "  Processing sub-category 35/41: Parathas\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 16 products so far...\n",
            "    Scroll 2: Loaded 16 products so far...\n",
            "    Scroll 3: Loaded 16 products so far...\n",
            "    Finished scrolling. Total attempts: 3\n",
            "    ‚úì Found 16 products\n",
            "  Processing sub-category 36/41: Samosas and Rolls\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 24 products so far...\n",
            "    Scroll 2: Loaded 29 products so far...\n",
            "    Scroll 3: Loaded 33 products so far...\n",
            "    Scroll 4: Loaded 33 products so far...\n",
            "    Scroll 5: Loaded 33 products so far...\n",
            "    Finished scrolling. Total attempts: 5\n",
            "    ‚úì Found 33 products\n",
            "  Processing sub-category 37/41: Detergents and Laundry Soaps\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 36 products so far...\n",
            "    Scroll 2: Loaded 48 products so far...\n",
            "    Scroll 3: Loaded 60 products so far...\n",
            "    Scroll 4: Loaded 68 products so far...\n",
            "    Scroll 5: Loaded 71 products so far...\n",
            "    Scroll 6: Loaded 71 products so far...\n",
            "    Scroll 7: Loaded 71 products so far...\n",
            "    Finished scrolling. Total attempts: 7\n",
            "    ‚úì Found 71 products\n",
            "  Processing sub-category 38/41: Fabric Care\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 25 products so far...\n",
            "    Scroll 2: Loaded 25 products so far...\n",
            "    Scroll 3: Loaded 25 products so far...\n",
            "    Finished scrolling. Total attempts: 3\n",
            "    ‚úì Found 25 products\n",
            "  Processing sub-category 39/41: Hangers and Accessories\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 5 products so far...\n",
            "    Scroll 2: Loaded 5 products so far...\n",
            "    Scroll 3: Loaded 5 products so far...\n",
            "    Finished scrolling. Total attempts: 3\n",
            "    ‚úì Found 5 products\n",
            "  Processing sub-category 40/41: Sauces and Seasonings\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 18 products so far...\n",
            "    Scroll 2: Loaded 18 products so far...\n",
            "    Scroll 3: Loaded 18 products so far...\n",
            "    Finished scrolling. Total attempts: 3\n",
            "    ‚úì Found 18 products\n",
            "  Processing sub-category 41/41: Spices and Herbs\n",
            "    Scrolling to load all products...\n",
            "    Scroll 1: Loaded 18 products so far...\n",
            "    Scroll 2: Loaded 18 products so far...\n",
            "    Scroll 3: Loaded 18 products so far...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:asyncio:Future exception was never retrieved\n",
            "future: <Future finished exception=TargetClosedError('Target page, context or browser has been closed\\nCall log:\\n  - navigating to \"https://www.metro-online.pk/home\", waiting until \"networkidle\"\\n')>\n",
            "playwright._impl._errors.TargetClosedError: Target page, context or browser has been closed\n",
            "Call log:\n",
            "  - navigating to \"https://www.metro-online.pk/home\", waiting until \"networkidle\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Finished scrolling. Total attempts: 3\n",
            "    ‚úì Found 18 products\n",
            "\n",
            "============================================================\n",
            "üíæ Saving results...\n",
            "‚úì Saved: metro_complete_hierarchy.json\n",
            "‚úì Saved: metro_subcategory_links.json\n",
            "‚úì Products saved to: metro_products_20251030_110758.csv\n",
            "‚úì JSON backup saved to: metro_products_20251030_110758.json\n",
            "\n",
            "üéâ SCRAPING COMPLETED!\n",
            "üìä Summary:\n",
            "   ‚Ä¢ Main Categories: 12\n",
            "   ‚Ä¢ Sub-categories: 41\n",
            "   ‚Ä¢ Products: 1238\n",
            "   ‚Ä¢ CSV File: metro_products_20251030_110758.csv\n",
            "   ‚Ä¢ JSON Backup: metro_products_20251030_110758.json\n",
            "\n",
            "üì¶ Sample Products (first 5):\n",
            "   1. Onions per 250GM - Rs. 54\n",
            "   2. Potato A Quality per 250GM - Rs. 24\n",
            "   3. Tomatoes Per 250GM - Rs. 75\n",
            "   4. Cucumber Per 250GM - Rs. 50\n",
            "   5. Potato White A-Grade Per 250GM - Rs. 24\n"
          ]
        }
      ]
    }
  ]
}